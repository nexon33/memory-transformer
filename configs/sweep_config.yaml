# Hyperparameter Sweep Configuration
# Use with: wandb sweep configs/sweep_config.yaml
# Then: wandb agent <sweep_id>

program: scripts/train_cloud.py
method: bayes  # bayes, grid, or random
metric:
  name: train/loss
  goal: minimize

parameters:
  # Learning rate (most important)
  learning-rate:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-3

  # Batch size
  batch-size:
    values: [16, 32, 64]

  # Memory configuration
  memory-size:
    values: [64, 128, 256]

  snapshot-interval:
    values: [2, 4, 8]

  # Model architecture (fixed for this sweep)
  model-config:
    value: "configs/medium_a100.yaml"

  # Training parameters
  max-steps:
    value: 10000  # Short runs for sweep

  # Dataset
  dataset:
    value: "c4"

command:
  - python
  - ${program}
  - ${args_no_hyphens}
  - --wandb-project
  - memory-transformer-sweep

# Sweep scheduling
early_terminate:
  type: hyperband
  min_iter: 1000
  eta: 2
  s: 3

# Run multiple experiments
run_cap: 20  # Maximum number of runs
